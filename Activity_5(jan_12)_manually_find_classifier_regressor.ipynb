{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP8j8Kv0hJFHKWsZXM4r9lS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/antonychackotc/machine-learning-supervised/blob/main/Activity_5(jan_12)_manually_find_classifier_regressor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **upload a file then train model on uploaded file data its Manualy select Linear Reggressor or decession tree Regressor or logistic Regressor or Decession tree classifier check file character one by one**"
      ],
      "metadata": {
        "id": "K9FM-MHhBFNw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q streamlit\n",
        "!pip install -q pyngrok\n",
        "!pip install -q localtunnel"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T1IB4bdTBUSU",
        "outputId": "3947383a-7531-4f82-fc27-4fb43fa09ea7"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.1/9.1 MB\u001b[0m \u001b[31m59.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m86.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: Could not find a version that satisfies the requirement localtunnel (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for localtunnel\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app1.py"
      ],
      "metadata": {
        "id": "7Jq8nZVdKFWc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iTxQaTDXA3ES",
        "outputId": "7440ed36-9c96-4dee-d82b-5eeb88a031a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app1.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile app1.py\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import streamlit as st\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, r2_score\n",
        "from sklearn.linear_model import LinearRegression, LogisticRegression, Ridge, Lasso, ElasticNet\n",
        "from sklearn.svm import SVR, SVC\n",
        "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier, GradientBoostingRegressor, GradientBoostingClassifier\n",
        "from sklearn.neighbors import KNeighborsRegressor, KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "\n",
        "# Function to evaluate models for regression\n",
        "def evaluate_regression(model, X_test, y_test):\n",
        "    y_pred = model.predict(X_test)\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    return r2 * 100\n",
        "\n",
        "# Function to evaluate models for classification\n",
        "def evaluate_classification(model, X_test, y_test):\n",
        "    y_pred = model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    return accuracy * 100\n",
        "\n",
        "# Function to apply a single model\n",
        "def apply_single_model(X_train, X_test, y_train, y_test, model_name, task_type):\n",
        "    model_map = {\n",
        "        \"Linear Regression\": LinearRegression(),\n",
        "        \"Polynomial Regression\": PolynomialFeatures(degree=2),\n",
        "        \"Ridge Regression\": Ridge(),\n",
        "        \"Lasso Regression\": Lasso(),\n",
        "        \"ElasticNet Regression\": ElasticNet(),\n",
        "        \"SVM Regression\": SVR(),\n",
        "        \"Decision Tree Regressor\": DecisionTreeRegressor(),\n",
        "        \"Random Forest Regressor\": RandomForestRegressor(),\n",
        "        \"Boosting Regressor\": GradientBoostingRegressor(),\n",
        "        \"KNN Regressor\": KNeighborsRegressor(),\n",
        "        \"Logistic Regression\": LogisticRegression(),\n",
        "        \"SVM Classifier\": SVC(),\n",
        "        \"Decision Tree Classifier\": DecisionTreeClassifier(),\n",
        "        \"Random Forest Classifier\": RandomForestClassifier(),\n",
        "        \"Boosting Classifier\": GradientBoostingClassifier(),\n",
        "        \"KNN Classifier\": KNeighborsClassifier(),\n",
        "        \"Naive Bayes Classifier\": GaussianNB(),\n",
        "    }\n",
        "\n",
        "    if model_name == \"Polynomial Regression\":\n",
        "        poly = PolynomialFeatures(degree=2)\n",
        "        X_train_poly = poly.fit_transform(X_train)\n",
        "        X_test_poly = poly.transform(X_test)\n",
        "        lin_reg = LinearRegression()\n",
        "        lin_reg.fit(X_train_poly, y_train)\n",
        "        score = evaluate_regression(lin_reg, X_test_poly, y_test)\n",
        "        trained_model = lin_reg\n",
        "    else:\n",
        "        model = model_map[model_name]\n",
        "        model.fit(X_train, y_train)\n",
        "        if task_type == 'regression':\n",
        "            score = evaluate_regression(model, X_test, y_test)\n",
        "        else:\n",
        "            score = evaluate_classification(model, X_test, y_test)\n",
        "        trained_model = model\n",
        "\n",
        "    return trained_model, score\n",
        "\n",
        "# Streamlit UI\n",
        "st.title(\"Automated Model Selection with Future Prediction\")\n",
        "\n",
        "# Tabs for better navigation\n",
        "tabs = st.tabs([\"Data Analysis\", \"Model Evaluation\", \"Future Prediction\"])\n",
        "\n",
        "with tabs[0]:  # Data Analysis Tab\n",
        "    st.header(\"Data Analysis\")\n",
        "    uploaded_file = st.file_uploader(\"Upload your dataset (CSV format):\", type=[\"csv\"])\n",
        "    if uploaded_file is not None:\n",
        "        data = pd.read_csv(uploaded_file)\n",
        "        st.write(\"Dataset Preview:\", data.head())\n",
        "\n",
        "        y_col = st.selectbox(\"Select the target column:\", data.columns)\n",
        "        if y_col:\n",
        "            y = data[y_col]\n",
        "            unique_values = y.nunique()\n",
        "\n",
        "            # Infer task type\n",
        "            if y.dtype in [np.int64, np.float64]:\n",
        "                if unique_values > 20:\n",
        "                    inferred_task_type = 'regression'\n",
        "                else:\n",
        "                    inferred_task_type = 'classification'\n",
        "            else:\n",
        "                inferred_task_type = 'classification'\n",
        "\n",
        "            st.write(f\"Inferred Task Type: **{inferred_task_type}**\")\n",
        "            if inferred_task_type == 'regression':\n",
        "                st.write(\"Suggested Model: **Linear Regression** or **Random Forest Regressor**\")\n",
        "            else:\n",
        "                st.write(\"Suggested Model: **Random Forest Classifier** or **Logistic Regression**\")\n",
        "\n",
        "with tabs[1]:  # Model Evaluation Tab\n",
        "    st.header(\"Model Evaluation\")\n",
        "    if uploaded_file is not None:\n",
        "        X_cols = st.multiselect(\"Select feature columns:\", [col for col in data.columns if col != y_col])\n",
        "        if not X_cols:\n",
        "            st.warning(\"Please select at least one feature column.\")\n",
        "        else:\n",
        "            X = data[X_cols]\n",
        "            y = data[y_col]\n",
        "\n",
        "            task_type = st.radio(\"Confirm Task Type:\", [\"regression\", \"classification\"])\n",
        "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "            model_list = [\n",
        "                \"Linear Regression\", \"Polynomial Regression\", \"Ridge Regression\", \"Lasso Regression\",\n",
        "                \"ElasticNet Regression\", \"SVM Regression\", \"Decision Tree Regressor\",\n",
        "                \"Random Forest Regressor\", \"Boosting Regressor\", \"KNN Regressor\"\n",
        "            ] if task_type == 'regression' else [\n",
        "                \"Logistic Regression\", \"SVM Classifier\", \"Decision Tree Classifier\",\n",
        "                \"Random Forest Classifier\", \"Boosting Classifier\", \"KNN Classifier\",\n",
        "                \"Naive Bayes Classifier\"\n",
        "            ]\n",
        "\n",
        "            selected_model = st.selectbox(\"Select a model to evaluate:\", model_list)\n",
        "            if st.button(\"Run Selected Model\"):\n",
        "                trained_model, score = apply_single_model(X_train, X_test, y_train, y_test, selected_model, task_type)\n",
        "                st.session_state[\"trained_model\"] = trained_model  # Save the trained model to session state\n",
        "                st.session_state[\"X_cols\"] = X_cols  # Save selected feature columns\n",
        "                st.success(f\"Model {selected_model} achieved a score of {score:.2f}%.\")\n",
        "\n",
        "with tabs[2]:  # Future Prediction Tab\n",
        "    st.header(\"Future Prediction\")\n",
        "\n",
        "    # Check if a dataset is uploaded and a model is trained\n",
        "    if uploaded_file is not None and \"trained_model\" in st.session_state:\n",
        "        st.write(\"Provide data for prediction using the existing features.\")\n",
        "\n",
        "        # Create a form for entering input data for prediction\n",
        "        input_data = {col: st.number_input(f\"Enter value for {col}:\", value=0.0) for col in st.session_state[\"X_cols\"]}\n",
        "\n",
        "        # Convert input data to a DataFrame\n",
        "        input_df = pd.DataFrame([input_data])\n",
        "        st.write(\"Input Data Preview:\")\n",
        "        st.write(input_df)\n",
        "\n",
        "        # Button to generate predictions\n",
        "        if st.button(\"Generate Prediction\"):\n",
        "            try:\n",
        "                # Retrieve the trained model from session state\n",
        "                trained_model = st.session_state[\"trained_model\"]\n",
        "                predictions = trained_model.predict(input_df)\n",
        "                st.write(\"Predictions:\", predictions)\n",
        "            except Exception as e:\n",
        "                st.error(f\"An error occurred during prediction: {e}\")\n",
        "    else:\n",
        "        st.warning(\"Please upload a dataset and evaluate a model in the 'Model Evaluation' tab before generating predictions.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "# Replace 'YOUR_AUTHTOKEN' with your actual ngrok authtoken\n",
        "ngrok.set_auth_token(\"2rI2XurhgC2fxlYDtteHntWpCJf_5b1kDx2SLmwgq8GukDEyc\")\n",
        "\n",
        "# Run the Streamlit app in the background\n",
        "!streamlit run app1.py &>/dev/null&\n",
        "\n",
        "# Create a public URL using ngrok\n",
        "try:\n",
        "    public_url = ngrok.connect(8501)\n",
        "    print(f\"Streamlit app is running at {public_url}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error: {e}\")\n",
        "    print(\"Trying to run with localtunnel\")\n",
        "    !streamlit run app1.py &>/content/logs.txt & npx localtunnel --port 8501"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LLmwaxkyBlOT",
        "outputId": "a4df906a-7d31-4a0d-de53-c99f77e68843"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Streamlit app is running at NgrokTunnel: \"https://1077-34-148-88-174.ngrok-free.app\" -> \"http://localhost:8501\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rojaE4v2Bm1X"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}